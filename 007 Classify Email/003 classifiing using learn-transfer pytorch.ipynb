{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d3fe0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e81a6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded data with encoding: utf-8\n",
      "\n",
      "DataFrame Head:\n",
      "   Spam                                            Message Unnamed: 2  \\\n",
      "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
      "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
      "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
      "\n",
      "  Unnamed: 3 Unnamed: 4  \n",
      "0        NaN        NaN  \n",
      "1        NaN        NaN  \n",
      "2        NaN        NaN  \n",
      "3        NaN        NaN  \n",
      "4        NaN        NaN  \n",
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Spam        5572 non-null   object\n",
      " 1   Message     5572 non-null   object\n",
      " 2   Unnamed: 2  50 non-null     object\n",
      " 3   Unnamed: 3  12 non-null     object\n",
      " 4   Unnamed: 4  6 non-null      object\n",
      "dtypes: object(5)\n",
      "memory usage: 217.8+ KB\n",
      "   Spam                                            Message\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Data Loading (from your provided code) ---\n",
    "def load_data(file_path):\n",
    "    encodings_to_try = ['utf-8', 'latin1', 'ISO-8859-1', 'cp1252']\n",
    "    for encoding in encodings_to_try:\n",
    "        try:\n",
    "            data = pd.read_csv(file_path, encoding=encoding)\n",
    "            print(f\"Successfully loaded data with encoding: {encoding}\")\n",
    "            return data\n",
    "        except UnicodeDecodeError:\n",
    "            print(f\"Failed to load with encoding: {encoding}\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred: {e}\")\n",
    "            return None\n",
    "    print(\"Could not load the file with any of the attempted encodings.\")\n",
    "    return None\n",
    "\n",
    "df = load_data('spam.csv')\n",
    "\n",
    "if df is not None:\n",
    "    print(\"\\nDataFrame Head:\")\n",
    "    print(df.head())\n",
    "    print(\"\\nDataFrame Info:\")\n",
    "    df.info()\n",
    "\n",
    "df = df[[\"Spam\", \"Message\"]]\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52d7b1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Spam                                            Message  \\\n",
      "0   ham  Go until jurong point, crazy.. Available only ...   \n",
      "1   ham                      Ok lar... Joking wif u oni...   \n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
      "3   ham  U dun say so early hor... U c already then say...   \n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...   \n",
      "\n",
      "                                   Processed_Message  \n",
      "0  go jurong point crazi avail bugi n great world...  \n",
      "1                              ok lar joke wif u oni  \n",
      "2  free entri wkli comp win fa cup final tkt may ...  \n",
      "3                u dun say earli hor u c alreadi say  \n",
      "4               nah think goe usf live around though  \n"
     ]
    }
   ],
   "source": [
    "# --- NLTK Downloads and Preprocessing Setup (from your provided code) ---\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stopwords = set(stopwords.words('english'))\n",
    "porterStemmer = PorterStemmer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    tokens = [token for token in tokens if token not in string.punctuation]\n",
    "    tokens = [token for token in tokens if token not in stopwords]\n",
    "    tokens = [porterStemmer.stem(token) for token in tokens]\n",
    "    processed_text = ' '.join(tokens)\n",
    "    processed_text = re.sub(r'http\\S+|www\\S+|https\\S+', '', processed_text, flags=re.MULTILINE)\n",
    "    processed_text = re.sub(r'\\@\\w+|\\#', '', processed_text)\n",
    "    processed_text = re.sub(r'\\d+', '', processed_text)\n",
    "    processed_text = re.sub(r'\\s+', ' ', processed_text).strip()\n",
    "    return processed_text\n",
    "\n",
    "df['Processed_Message'] = df['Message'].apply(preprocess_text)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "099f652b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Counter({0: 4825, 1: 747}), Resampled: Counter({0: 4825, 1: 4825})\n"
     ]
    }
   ],
   "source": [
    "# --- Feature and Target Variable Definition ---\n",
    "X = df['Processed_Message']\n",
    "y = df['Spam'].map({'ham':0,'spam':1 })\n",
    "# --- Oversampling with RandomOverSampler (Applied to original X and y) ---\n",
    "# It's better to split first, then oversample only the training data to avoid data leakage.\n",
    "# However, for simplicity and to directly follow your last provided code structure:\n",
    "# Ensure X is a DataFrame for RandomOverSampler if it's a Series\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled_df, y_resampled = ros.fit_resample(pd.DataFrame(X), y)\n",
    "\n",
    "# Convert X_resampled_df back to a Series or list of strings for BERT tokenization\n",
    "X_resampled_list = X_resampled_df.iloc[:, 0].tolist() # Get the 'Processed_Message' column as a list\n",
    "y_resampled_list = y_resampled.tolist()\n",
    "\n",
    "print(f\"Original: {Counter(y)}, Resampled: {Counter(y_resampled)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "634a31da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of X_train_raw: 7720\n",
      "Shape of y_train_raw: 7720\n",
      "Shape of X_test_raw: 1930\n",
      "Shape of y_test_raw: 1930\n",
      "Training set distribution: Counter({1: 3860, 0: 3860})\n",
      "Test set distribution: Counter({1: 965, 0: 965})\n"
     ]
    }
   ],
   "source": [
    "# --- Train-Test Split (after oversampling) ---\n",
    "# Note: When using oversampling *before* splitting, ensure your test set truly represents unseen data.\n",
    "# A more robust approach often is: split -> oversample train -> tokenize train/test.\n",
    "# But following your current structure, we'll split the already resampled data.\n",
    "X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(\n",
    "    X_resampled_list, y_resampled_list, test_size=0.2, random_state=42, stratify=y_resampled_list\n",
    ")\n",
    "\n",
    "print(f\"\\nShape of X_train_raw: {len(X_train_raw)}\")\n",
    "print(f\"Shape of y_train_raw: {len(y_train_raw)}\")\n",
    "print(f\"Shape of X_test_raw: {len(X_test_raw)}\")\n",
    "print(f\"Shape of y_test_raw: {len(y_test_raw)}\")\n",
    "print(f\"Training set distribution: {Counter(y_train_raw)}\")\n",
    "print(f\"Test set distribution: {Counter(y_test_raw)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee0916fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenizing training data...\n"
     ]
    }
   ],
   "source": [
    "# --- BERT Tokenization ---\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "max_length = 64 # Define the maximum length for padding\n",
    "\n",
    "print(\"\\nTokenizing training data...\")\n",
    "input_ids_train = []\n",
    "attention_masks_train = []\n",
    "for sent in X_train_raw:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        sent,\n",
    "        add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
    "        max_length=max_length,   # Pad & truncate all sentences\n",
    "        padding='max_length',    # Pad to max_length\n",
    "        truncation=True,         # Truncate to max_length\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt',     # Return PyTorch tensors\n",
    "    )\n",
    "    input_ids_train.append(encoded_dict['input_ids'])\n",
    "    attention_masks_train.append(encoded_dict['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d77e4999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists of tensors to single tensors\n",
    "input_ids_train = torch.cat(input_ids_train, dim=0)\n",
    "attention_masks_train = torch.cat(attention_masks_train, dim=0)\n",
    "labels_train = torch.tensor(y_train_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57126c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing test data...\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokenizing test data...\")\n",
    "input_ids_test = []\n",
    "attention_masks_test = []\n",
    "for sent in X_test_raw:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        sent,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_length,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt',\n",
    "    )\n",
    "    input_ids_test.append(encoded_dict['input_ids'])\n",
    "    attention_masks_test.append(encoded_dict['attention_mask'])\n",
    "\n",
    "input_ids_test = torch.cat(input_ids_test, dim=0)\n",
    "attention_masks_test = torch.cat(attention_masks_test, dim=0)\n",
    "labels_test = torch.tensor(y_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d548183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BERT inputs prepared.\n",
      "Shape of input_ids_train: torch.Size([7720, 64])\n",
      "Shape of labels_train: torch.Size([7720])\n",
      "Shape of input_ids_test: torch.Size([1930, 64])\n",
      "Shape of labels_test: torch.Size([1930])\n",
      "Number of training batches: 242\n",
      "Number of test batches: 61\n"
     ]
    }
   ],
   "source": [
    "# Create PyTorch DataLoaders\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "test_dataset = TensorDataset(input_ids_test, attention_masks_test, labels_test)\n",
    "test_sampler = SequentialSampler(test_dataset)\n",
    "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=batch_size)\n",
    "\n",
    "print(\"\\nBERT inputs prepared.\")\n",
    "print(f\"Shape of input_ids_train: {input_ids_train.shape}\")\n",
    "print(f\"Shape of labels_train: {labels_train.shape}\")\n",
    "print(f\"Shape of input_ids_test: {input_ids_test.shape}\")\n",
    "print(f\"Shape of labels_test: {labels_test.shape}\")\n",
    "print(f\"Number of training batches: {len(train_dataloader)}\")\n",
    "print(f\"Number of test batches: {len(test_dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1763d171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# --- BERT Model Fine-tuning ---\n",
    "# Device setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels = 2, # Binary classification\n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False,\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5da12de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer & Scheduler\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "epochs = 3 # A common number of epochs for BERT fine-tuning, adjust if needed\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f38ae173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute metrics\n",
    "def compute_metrics(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    \n",
    "    accuracy = accuracy_score(labels_flat, pred_flat)\n",
    "    f1 = f1_score(labels_flat, pred_flat, average='binary') # 'binary' for 2 classes\n",
    "    precision = precision_score(labels_flat, pred_flat, average='binary')\n",
    "    recall = recall_score(labels_flat, pred_flat, average='binary')\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "436197b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting BERT fine-tuning...\n",
      "======== Epoch 1 / 3 ========\n",
      "Training...\n",
      "  Batch 50 of 242.\n",
      "  Batch 100 of 242.\n",
      "  Batch 150 of 242.\n",
      "  Batch 200 of 242.\n",
      "\n",
      "  Average training loss: 0.0697\n",
      "\n",
      "Running Validation...\n",
      "  Validation Accuracy: 0.9928\n",
      "  Validation F1 Score: 0.9930\n",
      "  Validation Precision: 0.9954\n",
      "  Validation Recall: 0.9910\n",
      "======== Epoch 2 / 3 ========\n",
      "Training...\n",
      "  Batch 50 of 242.\n",
      "  Batch 100 of 242.\n",
      "  Batch 150 of 242.\n",
      "  Batch 200 of 242.\n",
      "\n",
      "  Average training loss: 0.0129\n",
      "\n",
      "Running Validation...\n",
      "  Validation Accuracy: 0.9933\n",
      "  Validation F1 Score: 0.9931\n",
      "  Validation Precision: 0.9887\n",
      "  Validation Recall: 0.9980\n",
      "======== Epoch 3 / 3 ========\n",
      "Training...\n",
      "  Batch 50 of 242.\n",
      "  Batch 100 of 242.\n",
      "  Batch 150 of 242.\n",
      "  Batch 200 of 242.\n",
      "\n",
      "  Average training loss: 0.0052\n",
      "\n",
      "Running Validation...\n",
      "  Validation Accuracy: 0.9954\n",
      "  Validation F1 Score: 0.9953\n",
      "  Validation Precision: 0.9908\n",
      "  Validation Recall: 1.0000\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "print(\"\\nStarting BERT fine-tuning...\")\n",
    "for epoch_i in range(0, epochs):\n",
    "    print(f'======== Epoch {epoch_i + 1} / {epochs} ========')\n",
    "    print('Training...')\n",
    "\n",
    "    total_train_loss = 0\n",
    "    model.train() # Set model to training mode\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            print(f'  Batch {step} of {len(train_dataloader)}.')\n",
    "\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        model.zero_grad() # Clear previously calculated gradients\n",
    "\n",
    "        outputs = model(b_input_ids,\n",
    "                        token_type_ids=None,\n",
    "                        attention_mask=b_input_mask,\n",
    "                        labels=b_labels) # labels are used to calculate loss internally by BertForSequenceClassification\n",
    "\n",
    "        loss = outputs.loss # Get the loss\n",
    "        total_train_loss += loss.item() # Add to total loss\n",
    "        loss.backward() # Perform a backward pass to calculate gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # Clip the norm of the gradients\n",
    "        optimizer.step() # Update model parameters\n",
    "        scheduler.step() # Update the learning rate\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    print(f\"\\n  Average training loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    print(\"\\nRunning Validation...\")\n",
    "    model.eval() # Set model to evaluation mode\n",
    "\n",
    "    eval_accuracy = []\n",
    "    eval_f1 = []\n",
    "    eval_precision = []\n",
    "    eval_recall = []\n",
    "    \n",
    "    for batch in test_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        with torch.no_grad(): # Disable gradient calculation for evaluation\n",
    "            outputs = model(b_input_ids,\n",
    "                            token_type_ids=None,\n",
    "                            attention_mask=b_input_mask)\n",
    "        \n",
    "        logits = outputs.logits # Get the logits (raw output scores)\n",
    "        \n",
    "        # Move logits and labels to CPU to compute metrics\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        metrics = compute_metrics(logits, label_ids)\n",
    "        eval_accuracy.append(metrics['accuracy'])\n",
    "        eval_f1.append(metrics['f1'])\n",
    "        eval_precision.append(metrics['precision'])\n",
    "        eval_recall.append(metrics['recall'])\n",
    "\n",
    "    print(f\"  Validation Accuracy: {np.mean(eval_accuracy):.4f}\")\n",
    "    print(f\"  Validation F1 Score: {np.mean(eval_f1):.4f}\")\n",
    "    print(f\"  Validation Precision: {np.mean(eval_precision):.4f}\")\n",
    "    print(f\"  Validation Recall: {np.mean(eval_recall):.4f}\")\n",
    "\n",
    "print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6bada01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./fine_tuned_bert_model/tokenizer_config.json',\n",
       " './fine_tuned_bert_model/special_tokens_map.json',\n",
       " './fine_tuned_bert_model/vocab.txt',\n",
       " './fine_tuned_bert_model/added_tokens.json')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained('./fine_tuned_bert_model/')\n",
    "tokenizer.save_pretrained('./fine_tuned_bert_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "011335be",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = BertForSequenceClassification.from_pretrained('./fine_tuned_bert_model/')\n",
    "loaded_tokenizer = BertTokenizer.from_pretrained('./fine_tuned_bert_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60814c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      1.00      1.00       956\n",
      "        spam       1.00      0.99      1.00       974\n",
      "\n",
      "    accuracy                           1.00      1930\n",
      "   macro avg       1.00      1.00      1.00      1930\n",
      "weighted avg       1.00      1.00      1.00      1930\n",
      "\n",
      "Shape of input_ids_train: torch.Size([7720, 64])\n",
      "Shape of labels_train: torch.Size([7720])\n",
      "Shape of input_ids_test: torch.Size([1930, 64])\n",
      "Shape of labels_test: torch.Size([1930])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "predictions, true_labels = [], []\n",
    "for batch in test_dataloader:\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = batch[2].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "    \n",
    "    logits = outputs.logits\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    predictions.append(logits)\n",
    "    true_labels.append(label_ids)\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "true_labels = np.concatenate(true_labels, axis=0)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(np.argmax(predictions, axis=1), true_labels, target_names=['ham', 'spam']))\n",
    "# Print shapes of the tensors\n",
    "print(f\"Shape of input_ids_train: {input_ids_train.shape}\")\n",
    "print(f\"Shape of labels_train: {labels_train.shape}\")\n",
    "print(f\"Shape of input_ids_test: {input_ids_test.shape}\")\n",
    "print(f\"Shape of labels_test: {labels_test.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d20e36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
