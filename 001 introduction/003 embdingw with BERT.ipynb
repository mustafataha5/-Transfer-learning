{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dfaf991-9f7f-4e65-81fe-3a65d7e15c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "260f5903-8694-42c4-a9a3-fe0483196c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ccae2663a041be948148b0d366dad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
    "model = BertModel.from_pretrained(\"bert-large-uncased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b8f13bd-fa21-429d-b172-2d4adc013c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9925940f-95da-4c61-9a1a-52b361359c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01e17dee-cc2a-4f34-a386-341684972410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1+cu118\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())  # Will be True if GPU is accessible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ced141da-a0dd-41e9-9d09-bde0da0e58fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_ids': tensor([[ 101, 1045, 2293, 4730,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])},\n",
       " {'input_ids': tensor([[  101,  1045,  5959, 16861,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"I love  programming\"\n",
    "text2 = \"i enjoy coding\"\n",
    "\n",
    "token1 = tokenizer(text1,return_tensors='pt')\n",
    "token2 = tokenizer(text2,return_tensors='pt')\n",
    "\n",
    "token1,token2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcbf7994-c176-470d-a065-dcb584271d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.0853, -0.5765, -0.6334,  ..., -0.8695, -0.6149,  0.1350],\n",
       "          [-0.0676, -0.5738, -0.2257,  ..., -0.2472, -0.1451, -0.2964],\n",
       "          [-0.3468, -0.2305, -0.0659,  ..., -0.3865,  0.0885,  0.0650],\n",
       "          [ 0.1064, -0.1514, -0.1836,  ...,  0.1019, -0.7688,  0.1537],\n",
       "          [-0.7420, -0.2230, -0.1059,  ..., -0.7624, -0.5671, -0.1679]]],\n",
       "        grad_fn=<NativeLayerNormBackward0>),\n",
       " tensor([[[-0.3767, -0.9047, -0.5043,  ..., -0.9634, -0.5423,  0.1136],\n",
       "          [-0.0535, -0.5905, -0.4027,  ..., -0.1526, -0.1549, -0.2906],\n",
       "          [-0.2147, -0.1513, -0.2134,  ..., -0.3337,  0.1453, -0.3278],\n",
       "          [ 0.1037,  0.0682, -0.3261,  ...,  0.0596, -0.7203, -0.0162],\n",
       "          [-0.9850,  0.2231,  0.0861,  ..., -0.6314, -0.7672, -0.4168]]],\n",
       "        grad_fn=<NativeLayerNormBackward0>))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding1 = model(**token1)['last_hidden_state']\n",
    "embedding2 = model(**token2)['last_hidden_state']\n",
    "\n",
    "embedding1,embedding2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1524d17a-4f9d-4024-880e-8dffc088ecda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1 shape: torch.Size([1, 5, 1024])\n",
      "Embedding 2 shape: torch.Size([1, 5, 1024])\n"
     ]
    }
   ],
   "source": [
    "print(\"Embedding 1 shape:\", embedding1.shape)\n",
    "print(\"Embedding 2 shape:\", embedding2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa0992c3-2975-4368-bf23-03b628a7f8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "mean_embedding1 = np.mean(embedding1.detach().numpy(),axis=1)\n",
    "mean_embedding2 = np.mean(embedding2.detach().numpy(),axis=1)\n",
    "# mean_embedding3 = np.mean(embedding3.detach().numpy(),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0f80a19-eb5a-4b69-a1a9-9742b0329190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9234957]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_similarity(mean_embedding1,mean_embedding2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c707129f-1b0c-42c6-a256-3c73de4e2046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.9234957]], dtype=float32),\n",
       " array([[0.73619556]], dtype=float32),\n",
       " array([[0.7747085]], dtype=float32))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"I love  programming\"\n",
    "text2 = \"i enjoy coding\"\n",
    "text3 = \"I ate apple everyday\"\n",
    "\n",
    "token1 = tokenizer(text1,return_tensors='pt')\n",
    "token2 = tokenizer(text2,return_tensors='pt')\n",
    "token3 = tokenizer(text3,return_tensors='pt')\n",
    "\n",
    "embedding1 = model(**token1)['last_hidden_state']\n",
    "embedding2 = model(**token2)['last_hidden_state']\n",
    "embedding3 = model(**token3)['last_hidden_state']\n",
    "\n",
    "\n",
    "mean_embedding1 = np.mean(embedding1.detach().numpy(),axis=1)\n",
    "mean_embedding2 = np.mean(embedding2.detach().numpy(),axis=1)\n",
    "mean_embedding3 = np.mean(embedding3.detach().numpy(),axis=1)\n",
    "\n",
    "cosine_similarity(mean_embedding1,mean_embedding2),cosine_similarity(mean_embedding1,mean_embedding3),cosine_similarity(mean_embedding3,mean_embedding2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93e1d9d9-6472-4b3a-84c1-4f7f3be4c12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'I love programming' and 'i enjoy coding': 0.9235\n",
      "Similarity between 'I love programming' and 'I hat dogs': 0.7430\n",
      "Similarity between 'I hat dogs' and 'i enjoy coding': 0.7368\n"
     ]
    }
   ],
   "source": [
    "text1 = \"I love programming\"\n",
    "text2 = \"i enjoy coding\"\n",
    "text3 = \"I hat dogs\"\n",
    "\n",
    "token1 = tokenizer(text1, return_tensors='pt')\n",
    "token2 = tokenizer(text2, return_tensors='pt')\n",
    "token3 = tokenizer(text3, return_tensors='pt')\n",
    "\n",
    "embedding1 = model(**token1)['last_hidden_state']\n",
    "embedding2 = model(**token2)['last_hidden_state']\n",
    "embedding3 = model(**token3)['last_hidden_state']\n",
    "\n",
    "# Detach from graph and convert to numpy, then compute mean along axis 1 (sequence length)\n",
    "# The output of mean will be (batch_size, hidden_size)\n",
    "mean_embedding1 = np.mean(embedding1.detach().numpy(), axis=1)\n",
    "mean_embedding2 = np.mean(embedding2.detach().numpy(), axis=1)\n",
    "mean_embedding3 = np.mean(embedding3.detach().numpy(), axis=1)\n",
    "\n",
    "# Ensure the embeddings are 2D arrays (even if batch_size is 1)\n",
    "# The cosine_similarity function from sklearn expects 2D arrays\n",
    "# (n_samples, n_features). If batch_size is 1, mean_embeddingX will be (1, hidden_size).\n",
    "# If you don't use .reshape(1, -1), it might be (hidden_size,) which will cause an error.\n",
    "mean_embedding1 = mean_embedding1.reshape(1, -1)\n",
    "mean_embedding2 = mean_embedding2.reshape(1, -1)\n",
    "mean_embedding3 = mean_embedding3.reshape(1, -1)\n",
    "\n",
    "# Compute cosine similarities\n",
    "sim_1_2 = cosine_similarity(mean_embedding1, mean_embedding2)\n",
    "sim_1_3 = cosine_similarity(mean_embedding1, mean_embedding3)\n",
    "sim_3_2 = cosine_similarity(mean_embedding3, mean_embedding2)\n",
    "\n",
    "print(f\"Similarity between '{text1}' and '{text2}': {sim_1_2[0][0]:.4f}\")\n",
    "print(f\"Similarity between '{text1}' and '{text3}': {sim_1_3[0][0]:.4f}\")\n",
    "print(f\"Similarity between '{text3}' and '{text2}': {sim_3_2[0][0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78897656-a57c-4400-bdad-ef2e7078bb9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
