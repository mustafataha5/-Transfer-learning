{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a85a9fa3-a1ab-4933-8359-c2eac1e97649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f98dcd2bb4f458090c84f92ab958e71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/39.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b58e700e8df408ebf71a1972f8629cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ebf1d1a2434dfd92e581e6a2644f11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4400e84f3ab04cd1b251a7af247fe1b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/953 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4863d04ddf04248b1126a5e2952b737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/669M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "model_name= 'nlptown/bert-base-multilingual-uncased-sentiment'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c1ce213-33ba-4a2e-ab89-d4a9adf586c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted sentiment is: 5 stars (very positive)\n"
     ]
    }
   ],
   "source": [
    "sentiment_labels = {\n",
    "    0: \"1 star (very negative)\",\n",
    "    1: \"2 stars (negative)\",\n",
    "    2: \"3 stars (neutral)\",\n",
    "    3: \"4 stars (positive)\",\n",
    "    4: \"5 stars (very positive)\"\n",
    "}\n",
    "\n",
    "# Example usage:\n",
    "predicted_class_id = 4 # (from model output, 0-indexed)\n",
    "print(f\"The predicted sentiment is: {sentiment_labels[predicted_class_id]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29e82155-0bb5-4f2c-b546-dbfb919f755e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c64377a-0d4a-4891-a404-ba0f13d338fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your text\n",
    "text_to_analyze = \"I am very happy with this service!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f526192-8f73-4cbf-9161-cb9581e1b630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Tokenize the input text\n",
    "# return_tensors='pt' ensures PyTorch tensors are returned\n",
    "inputs = tokenizer(text_to_analyze, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9dbb353-e8b5-47fa-8f58-dc19f26e99ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**inputs) # Unpack the inputs dictionary using **\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcca6c9c-f598-4906-a2ee-985ae89c022c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = outputs.logits\n",
    "\n",
    "# 3. Convert logits to probabilities (optional, but good for understanding confidence)\n",
    "probabilities = torch.softmax(logits, dim=1)\n",
    "\n",
    "# 4. Get the predicted class (star rating)\n",
    "# The argmax finds the index of the highest probability\n",
    "predicted_class_id = torch.argmax(probabilities, dim=1).item()\n",
    "\n",
    "# Map the 0-indexed class ID to the 1-5 star rating\n",
    "predicted_star_rating = predicted_class_id + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e557db0-8b5f-4d8e-a8cb-aa5007f8c175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: 'I am very happy with this service!'\n",
      "Logits: tensor([[-2.6536, -2.9549, -0.7673,  1.9842,  3.4692]])\n",
      "Probabilities: tensor([[0.0018, 0.0013, 0.0116, 0.1820, 0.8034]])\n",
      "Predicted class ID (0-indexed): 4\n",
      "Predicted Star Rating: 5 (5 stars (very positive))\n",
      "Confidence Score for Predicted Star: 0.8034\n",
      "\n",
      "Probabilities for each star rating:\n",
      "  1 star: 0.0018\n",
      "  2 star: 0.0013\n",
      "  3 star: 0.0116\n",
      "  4 star: 0.1820\n",
      "  5 star: 0.8034\n"
     ]
    }
   ],
   "source": [
    "print(f\"Text: '{text_to_analyze}'\")\n",
    "print(f\"Logits: {logits}\")\n",
    "print(f\"Probabilities: {probabilities}\")\n",
    "print(f\"Predicted class ID (0-indexed): {predicted_class_id}\")\n",
    "print(f\"Predicted Star Rating: {predicted_star_rating} ({sentiment_labels[predicted_class_id]})\")\n",
    "print(f\"Confidence Score for Predicted Star: {probabilities[0][predicted_class_id].item():.4f}\")\n",
    "\n",
    "# You can also get the confidence for all stars\n",
    "print(\"\\nProbabilities for each star rating:\")\n",
    "for i, prob in enumerate(probabilities[0]):\n",
    "    print(f\"  {i+1} star: {prob.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35146016-13b2-4601-bcdf-52e6d223d410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.0375, -1.5210,  0.6265,  1.5049,  1.1485]])\n",
      "Predicted Star Rating: 4 (4 stars (positive))\n"
     ]
    }
   ],
   "source": [
    "text= \" apply is  good \"\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs) # Unpack the inputs dictionary using **\n",
    "logits = outputs.logits\n",
    "print(logits)\n",
    "# probabilities = torch.softmax(logits, dim=1)\n",
    "# The argmax finds the index of the highest probability\n",
    "predicted_class_id = torch.argmax(logits, dim=1).item()\n",
    "\n",
    "# Map the 0-indexed class ID to the 1-5 star rating\n",
    "predicted_star_rating = predicted_class_id + 1\n",
    "print(f\"Predicted Star Rating: {predicted_star_rating} ({sentiment_labels[predicted_class_id]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2da59f3-fa4a-4751-90a6-cf78614574c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f71ba1-2961-4494-802f-fedeac663fe8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
