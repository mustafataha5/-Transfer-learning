{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d15b882",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import numpy as np\n",
    "import torch\n",
    "import tensorflow as tf \n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "748565da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import re\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f58e924e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove links\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "\n",
    "    # Remove usernames\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "\n",
    "    # Replace underscores with space\n",
    "    text = text.replace('_', ' ')\n",
    "\n",
    "    \n",
    "    # Remove hashtag symbol but keep the word\n",
    "    text = re.sub(r'#', '', text)\n",
    "\n",
    "    # Remove emojis (basic unicode emoji pattern)\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags\n",
    "                               u\"\\u2600-\\u26FF\"          # miscellaneous symbols\n",
    "                               u\"\\u2700-\\u27BF\"          # dingbats\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "\n",
    "    # Remove numbers and punctuations\n",
    "    del_chars = string.punctuation + \"0123456789\" + \"ØŒØ›ØŸÙ€â€œâ€\"\n",
    "    text = ''.join(char for char in text if char not in del_chars)\n",
    "\n",
    "    # Strip extra whitespace\n",
    "    text = text.strip()\n",
    "\n",
    "    # Tokenization and stopword removal\n",
    "    stop_words = set(stopwords.words('arabic'))\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91469998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ø­Ù‚ÙˆÙ‚ Ø§Ù„Ù…Ø±Ø£Ø© ğŸ’šğŸ’šğŸ’š https://t.co/Mzf90Ta5g1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @___IHAVENOIDEA: Ø­Ù‚ÙˆÙ‚ Ø§Ù„Ù…Ø±Ø£Ø© ÙÙŠ Ø§Ù„Ø¥Ø³Ù„Ø§Ù…. ht...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @saud_talep: Retweeted Ù„Ø¬Ù†Ø© Ø§Ù„ØªÙ†Ù…ÙŠØ© Ø¨Ø´Ø¨Ø±Ø§ (...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @MojKsa: Ø­Ù‚ÙˆÙ‚ Ø§Ù„Ù…Ø±Ø£Ø© Ø§Ù„ØªÙŠ ØªØ¶Ù…Ù†Ù‡Ø§ Ù„Ù‡Ø§ ÙˆØ²Ø§Ø±Ø© ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @abm112211: ÙˆÙ„ÙŠ Ø§Ù…Ø± Ø§Ù„Ø²ÙˆØ¬Ø© Ø§Ùˆ ÙˆÙ„ÙŠ Ø§Ù„Ø²ÙˆØ¬Ø© Ø§Ùˆ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4247</th>\n",
       "      <td>#ØºØ±Ø¯_Ø¨Ø­Ø¨Ùƒ_Ù„Ù…Ø­Ù…Ø¯_Ø¨Ù†_Ø³Ù„Ù…Ø§Ù† â¤ï¸</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4248</th>\n",
       "      <td>#ØºØ±Ø¯_Ø¨Ø­Ø¨Ùƒ_Ù„Ù…Ø­Ù…Ø¯_Ø¨Ù†_Ø³Ù„Ù…Ø§Ù† \\n Ù…Ø­Ù…Ø¯Ø¨Ù† Ø³Ù„Ù…Ø§Ù† Ø§Ø­Ø¨Ù‡ ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4249</th>\n",
       "      <td>#ØºØ±Ø¯_Ø¨Ø­Ø¨Ùƒ_Ù„Ù…Ø­Ù…Ø¯_Ø¨Ù†_Ø³Ù„Ù…Ø§Ù† \\n Ø§Ù„Ù„Ù‡ ÙŠØ­ÙØ¸Ùƒ ÙŠØ§ Ø°Ø®Ø± ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4250</th>\n",
       "      <td>#ØºØ±Ø¯_Ø¨Ø­Ø¨Ùƒ_Ù„Ù…Ø­Ù…Ø¯_Ø¨Ù†_Ø³Ù„Ù…Ø§Ù† \\n \\n Ø§Ù„Ù„Ù‡ ÙŠØ­ÙØ¸Ù‡ ÙˆÙŠØ­Ù…...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4251</th>\n",
       "      <td>#ØºØ±Ø¯_Ø¨Ø­Ø¨Ùƒ_Ù„Ù…Ø­Ù…Ø¯_Ø¨Ù†_Ø³Ù„Ù…Ø§Ù† \\n \\n Ø§Ø­Ø¨Ù‡ Ø§Ø­Ø¨Ù‡ ÙŠØ§Ø®ÙŠ ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4252 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  Sentiment\n",
       "0               Ø­Ù‚ÙˆÙ‚ Ø§Ù„Ù…Ø±Ø£Ø© ğŸ’šğŸ’šğŸ’š https://t.co/Mzf90Ta5g1          1\n",
       "1     RT @___IHAVENOIDEA: Ø­Ù‚ÙˆÙ‚ Ø§Ù„Ù…Ø±Ø£Ø© ÙÙŠ Ø§Ù„Ø¥Ø³Ù„Ø§Ù…. ht...          1\n",
       "2     RT @saud_talep: Retweeted Ù„Ø¬Ù†Ø© Ø§Ù„ØªÙ†Ù…ÙŠØ© Ø¨Ø´Ø¨Ø±Ø§ (...          1\n",
       "3     RT @MojKsa: Ø­Ù‚ÙˆÙ‚ Ø§Ù„Ù…Ø±Ø£Ø© Ø§Ù„ØªÙŠ ØªØ¶Ù…Ù†Ù‡Ø§ Ù„Ù‡Ø§ ÙˆØ²Ø§Ø±Ø© ...          1\n",
       "4     RT @abm112211: ÙˆÙ„ÙŠ Ø§Ù…Ø± Ø§Ù„Ø²ÙˆØ¬Ø© Ø§Ùˆ ÙˆÙ„ÙŠ Ø§Ù„Ø²ÙˆØ¬Ø© Ø§Ùˆ...          1\n",
       "...                                                 ...        ...\n",
       "4247                        #ØºØ±Ø¯_Ø¨Ø­Ø¨Ùƒ_Ù„Ù…Ø­Ù…Ø¯_Ø¨Ù†_Ø³Ù„Ù…Ø§Ù† â¤ï¸          1\n",
       "4248  #ØºØ±Ø¯_Ø¨Ø­Ø¨Ùƒ_Ù„Ù…Ø­Ù…Ø¯_Ø¨Ù†_Ø³Ù„Ù…Ø§Ù† \\n Ù…Ø­Ù…Ø¯Ø¨Ù† Ø³Ù„Ù…Ø§Ù† Ø§Ø­Ø¨Ù‡ ...          1\n",
       "4249  #ØºØ±Ø¯_Ø¨Ø­Ø¨Ùƒ_Ù„Ù…Ø­Ù…Ø¯_Ø¨Ù†_Ø³Ù„Ù…Ø§Ù† \\n Ø§Ù„Ù„Ù‡ ÙŠØ­ÙØ¸Ùƒ ÙŠØ§ Ø°Ø®Ø± ...          1\n",
       "4250  #ØºØ±Ø¯_Ø¨Ø­Ø¨Ùƒ_Ù„Ù…Ø­Ù…Ø¯_Ø¨Ù†_Ø³Ù„Ù…Ø§Ù† \\n \\n Ø§Ù„Ù„Ù‡ ÙŠØ­ÙØ¸Ù‡ ÙˆÙŠØ­Ù…...          1\n",
       "4251  #ØºØ±Ø¯_Ø¨Ø­Ø¨Ùƒ_Ù„Ù…Ø­Ù…Ø¯_Ø¨Ù†_Ø³Ù„Ù…Ø§Ù† \\n \\n Ø§Ø­Ø¨Ù‡ Ø§Ø­Ø¨Ù‡ ÙŠØ§Ø®ÙŠ ...          1\n",
       "\n",
       "[4252 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read the CSV file arabic sentiment analysis dataset\n",
    "df = pd.read_csv('./data/Arabic Sentiment Analysis Dataset - SS2030.csv',sep=\";\", encoding='utf-8', on_bad_lines='skip')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c584eb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply it to your dataframe\n",
    "df['cleaned_text'] = df['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f107c79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4252 entries, 0 to 4251\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   text          4252 non-null   object\n",
      " 1   Sentiment     4252 non-null   int64 \n",
      " 2   cleaned_text  4252 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 99.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7d43ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ø­Ù‚ÙˆÙ‚ Ø§Ù„Ù…Ø±Ø£Ø© ğŸ’šğŸ’šğŸ’š https://t.co/Mzf90Ta5g1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ø­Ù‚ÙˆÙ‚ Ø§Ù„Ù…Ø±Ø£Ø©</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @___IHAVENOIDEA: Ø­Ù‚ÙˆÙ‚ Ø§Ù„Ù…Ø±Ø£Ø© ÙÙŠ Ø§Ù„Ø¥Ø³Ù„Ø§Ù…. ht...</td>\n",
       "      <td>1</td>\n",
       "      <td>rt Ø­Ù‚ÙˆÙ‚ Ø§Ù„Ù…Ø±Ø£Ø© Ø§Ù„Ø¥Ø³Ù„Ø§Ù…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @saud_talep: Retweeted Ù„Ø¬Ù†Ø© Ø§Ù„ØªÙ†Ù…ÙŠØ© Ø¨Ø´Ø¨Ø±Ø§ (...</td>\n",
       "      <td>1</td>\n",
       "      <td>rt retweeted Ù„Ø¬Ù†Ø© Ø§Ù„ØªÙ†Ù…ÙŠØ© Ø¨Ø´Ø¨Ø±Ø§ Ø²Ø§Ù„ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ù…Ø³...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @MojKsa: Ø­Ù‚ÙˆÙ‚ Ø§Ù„Ù…Ø±Ø£Ø© Ø§Ù„ØªÙŠ ØªØ¶Ù…Ù†Ù‡Ø§ Ù„Ù‡Ø§ ÙˆØ²Ø§Ø±Ø© ...</td>\n",
       "      <td>1</td>\n",
       "      <td>rt Ø­Ù‚ÙˆÙ‚ Ø§Ù„Ù…Ø±Ø£Ø© ØªØ¶Ù…Ù†Ù‡Ø§ ÙˆØ²Ø§Ø±Ø© Ø§Ù„Ø¹Ø¯Ù„</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @abm112211: ÙˆÙ„ÙŠ Ø§Ù…Ø± Ø§Ù„Ø²ÙˆØ¬Ø© Ø§Ùˆ ÙˆÙ„ÙŠ Ø§Ù„Ø²ÙˆØ¬Ø© Ø§Ùˆ...</td>\n",
       "      <td>1</td>\n",
       "      <td>rt ÙˆÙ„ÙŠ Ø§Ù…Ø± Ø§Ù„Ø²ÙˆØ¬Ø© Ø§Ùˆ ÙˆÙ„ÙŠ Ø§Ù„Ø²ÙˆØ¬Ø© Ø§Ùˆ ÙˆÙ„ÙŠ Ø§Ù„Ù…Ø±Ø§Ø© ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4247</th>\n",
       "      <td>#ØºØ±Ø¯_Ø¨Ø­Ø¨Ùƒ_Ù„Ù…Ø­Ù…Ø¯_Ø¨Ù†_Ø³Ù„Ù…Ø§Ù† â¤ï¸</td>\n",
       "      <td>1</td>\n",
       "      <td>ØºØ±Ø¯ Ø¨Ø­Ø¨Ùƒ Ù„Ù…Ø­Ù…Ø¯ Ø¨Ù† Ø³Ù„Ù…Ø§Ù†</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4248</th>\n",
       "      <td>#ØºØ±Ø¯_Ø¨Ø­Ø¨Ùƒ_Ù„Ù…Ø­Ù…Ø¯_Ø¨Ù†_Ø³Ù„Ù…Ø§Ù† \\n Ù…Ø­Ù…Ø¯Ø¨Ù† Ø³Ù„Ù…Ø§Ù† Ø§Ø­Ø¨Ù‡ ...</td>\n",
       "      <td>1</td>\n",
       "      <td>ØºØ±Ø¯ Ø¨Ø­Ø¨Ùƒ Ù„Ù…Ø­Ù…Ø¯ Ø¨Ù† Ø³Ù„Ù…Ø§Ù† Ù…Ø­Ù…Ø¯Ø¨Ù† Ø³Ù„Ù…Ø§Ù† Ø§Ø­Ø¨Ù‡ Ø§Ù„Ù„Ù‡...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4249</th>\n",
       "      <td>#ØºØ±Ø¯_Ø¨Ø­Ø¨Ùƒ_Ù„Ù…Ø­Ù…Ø¯_Ø¨Ù†_Ø³Ù„Ù…Ø§Ù† \\n Ø§Ù„Ù„Ù‡ ÙŠØ­ÙØ¸Ùƒ ÙŠØ§ Ø°Ø®Ø± ...</td>\n",
       "      <td>1</td>\n",
       "      <td>ØºØ±Ø¯ Ø¨Ø­Ø¨Ùƒ Ù„Ù…Ø­Ù…Ø¯ Ø¨Ù† Ø³Ù„Ù…Ø§Ù† Ø§Ù„Ù„Ù‡ ÙŠØ­ÙØ¸Ùƒ Ø°Ø®Ø± Ø§Ù„ÙˆØ·Ù† Ùˆ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4250</th>\n",
       "      <td>#ØºØ±Ø¯_Ø¨Ø­Ø¨Ùƒ_Ù„Ù…Ø­Ù…Ø¯_Ø¨Ù†_Ø³Ù„Ù…Ø§Ù† \\n \\n Ø§Ù„Ù„Ù‡ ÙŠØ­ÙØ¸Ù‡ ÙˆÙŠØ­Ù…...</td>\n",
       "      <td>1</td>\n",
       "      <td>ØºØ±Ø¯ Ø¨Ø­Ø¨Ùƒ Ù„Ù…Ø­Ù…Ø¯ Ø¨Ù† Ø³Ù„Ù…Ø§Ù† Ø§Ù„Ù„Ù‡ ÙŠØ­ÙØ¸Ù‡ ÙˆÙŠØ­Ù…ÙŠÙ‡ ÙˆÙŠÙ‚Ùˆ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4251</th>\n",
       "      <td>#ØºØ±Ø¯_Ø¨Ø­Ø¨Ùƒ_Ù„Ù…Ø­Ù…Ø¯_Ø¨Ù†_Ø³Ù„Ù…Ø§Ù† \\n \\n Ø§Ø­Ø¨Ù‡ Ø§Ø­Ø¨Ù‡ ÙŠØ§Ø®ÙŠ ...</td>\n",
       "      <td>1</td>\n",
       "      <td>ØºØ±Ø¯ Ø¨Ø­Ø¨Ùƒ Ù„Ù…Ø­Ù…Ø¯ Ø¨Ù† Ø³Ù„Ù…Ø§Ù† Ø§Ø­Ø¨Ù‡ Ø§Ø­Ø¨Ù‡ ÙŠØ§Ø®ÙŠ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4252 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  Sentiment  \\\n",
       "0               Ø­Ù‚ÙˆÙ‚ Ø§Ù„Ù…Ø±Ø£Ø© ğŸ’šğŸ’šğŸ’š https://t.co/Mzf90Ta5g1          1   \n",
       "1     RT @___IHAVENOIDEA: Ø­Ù‚ÙˆÙ‚ Ø§Ù„Ù…Ø±Ø£Ø© ÙÙŠ Ø§Ù„Ø¥Ø³Ù„Ø§Ù…. ht...          1   \n",
       "2     RT @saud_talep: Retweeted Ù„Ø¬Ù†Ø© Ø§Ù„ØªÙ†Ù…ÙŠØ© Ø¨Ø´Ø¨Ø±Ø§ (...          1   \n",
       "3     RT @MojKsa: Ø­Ù‚ÙˆÙ‚ Ø§Ù„Ù…Ø±Ø£Ø© Ø§Ù„ØªÙŠ ØªØ¶Ù…Ù†Ù‡Ø§ Ù„Ù‡Ø§ ÙˆØ²Ø§Ø±Ø© ...          1   \n",
       "4     RT @abm112211: ÙˆÙ„ÙŠ Ø§Ù…Ø± Ø§Ù„Ø²ÙˆØ¬Ø© Ø§Ùˆ ÙˆÙ„ÙŠ Ø§Ù„Ø²ÙˆØ¬Ø© Ø§Ùˆ...          1   \n",
       "...                                                 ...        ...   \n",
       "4247                        #ØºØ±Ø¯_Ø¨Ø­Ø¨Ùƒ_Ù„Ù…Ø­Ù…Ø¯_Ø¨Ù†_Ø³Ù„Ù…Ø§Ù† â¤ï¸          1   \n",
       "4248  #ØºØ±Ø¯_Ø¨Ø­Ø¨Ùƒ_Ù„Ù…Ø­Ù…Ø¯_Ø¨Ù†_Ø³Ù„Ù…Ø§Ù† \\n Ù…Ø­Ù…Ø¯Ø¨Ù† Ø³Ù„Ù…Ø§Ù† Ø§Ø­Ø¨Ù‡ ...          1   \n",
       "4249  #ØºØ±Ø¯_Ø¨Ø­Ø¨Ùƒ_Ù„Ù…Ø­Ù…Ø¯_Ø¨Ù†_Ø³Ù„Ù…Ø§Ù† \\n Ø§Ù„Ù„Ù‡ ÙŠØ­ÙØ¸Ùƒ ÙŠØ§ Ø°Ø®Ø± ...          1   \n",
       "4250  #ØºØ±Ø¯_Ø¨Ø­Ø¨Ùƒ_Ù„Ù…Ø­Ù…Ø¯_Ø¨Ù†_Ø³Ù„Ù…Ø§Ù† \\n \\n Ø§Ù„Ù„Ù‡ ÙŠØ­ÙØ¸Ù‡ ÙˆÙŠØ­Ù…...          1   \n",
       "4251  #ØºØ±Ø¯_Ø¨Ø­Ø¨Ùƒ_Ù„Ù…Ø­Ù…Ø¯_Ø¨Ù†_Ø³Ù„Ù…Ø§Ù† \\n \\n Ø§Ø­Ø¨Ù‡ Ø§Ø­Ø¨Ù‡ ÙŠØ§Ø®ÙŠ ...          1   \n",
       "\n",
       "                                           cleaned_text  \n",
       "0                                           Ø­Ù‚ÙˆÙ‚ Ø§Ù„Ù…Ø±Ø£Ø©  \n",
       "1                                rt Ø­Ù‚ÙˆÙ‚ Ø§Ù„Ù…Ø±Ø£Ø© Ø§Ù„Ø¥Ø³Ù„Ø§Ù…  \n",
       "2     rt retweeted Ù„Ø¬Ù†Ø© Ø§Ù„ØªÙ†Ù…ÙŠØ© Ø¨Ø´Ø¨Ø±Ø§ Ø²Ø§Ù„ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ù…Ø³...  \n",
       "3                     rt Ø­Ù‚ÙˆÙ‚ Ø§Ù„Ù…Ø±Ø£Ø© ØªØ¶Ù…Ù†Ù‡Ø§ ÙˆØ²Ø§Ø±Ø© Ø§Ù„Ø¹Ø¯Ù„  \n",
       "4     rt ÙˆÙ„ÙŠ Ø§Ù…Ø± Ø§Ù„Ø²ÙˆØ¬Ø© Ø§Ùˆ ÙˆÙ„ÙŠ Ø§Ù„Ø²ÙˆØ¬Ø© Ø§Ùˆ ÙˆÙ„ÙŠ Ø§Ù„Ù…Ø±Ø§Ø© ...  \n",
       "...                                                 ...  \n",
       "4247                            ØºØ±Ø¯ Ø¨Ø­Ø¨Ùƒ Ù„Ù…Ø­Ù…Ø¯ Ø¨Ù† Ø³Ù„Ù…Ø§Ù†  \n",
       "4248  ØºØ±Ø¯ Ø¨Ø­Ø¨Ùƒ Ù„Ù…Ø­Ù…Ø¯ Ø¨Ù† Ø³Ù„Ù…Ø§Ù† Ù…Ø­Ù…Ø¯Ø¨Ù† Ø³Ù„Ù…Ø§Ù† Ø§Ø­Ø¨Ù‡ Ø§Ù„Ù„Ù‡...  \n",
       "4249  ØºØ±Ø¯ Ø¨Ø­Ø¨Ùƒ Ù„Ù…Ø­Ù…Ø¯ Ø¨Ù† Ø³Ù„Ù…Ø§Ù† Ø§Ù„Ù„Ù‡ ÙŠØ­ÙØ¸Ùƒ Ø°Ø®Ø± Ø§Ù„ÙˆØ·Ù† Ùˆ...  \n",
       "4250  ØºØ±Ø¯ Ø¨Ø­Ø¨Ùƒ Ù„Ù…Ø­Ù…Ø¯ Ø¨Ù† Ø³Ù„Ù…Ø§Ù† Ø§Ù„Ù„Ù‡ ÙŠØ­ÙØ¸Ù‡ ÙˆÙŠØ­Ù…ÙŠÙ‡ ÙˆÙŠÙ‚Ùˆ...  \n",
       "4251             ØºØ±Ø¯ Ø¨Ø­Ø¨Ùƒ Ù„Ù…Ø­Ù…Ø¯ Ø¨Ù† Ø³Ù„Ù…Ø§Ù† Ø§Ø­Ø¨Ù‡ Ø§Ø­Ø¨Ù‡ ÙŠØ§Ø®ÙŠ  \n",
       "\n",
       "[4252 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71622a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['cleaned_text'].values\n",
    "y = df['Sentiment'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbc353a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4252, 128)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X)\n",
    "X_seq = tokenizer.texts_to_sequences(X)\n",
    "X_padding = pad_sequences(X_seq,maxlen=128 ,padding='post')\n",
    "X_padding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84edabb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 23556\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1  # +1 for padding token\n",
    "print(f\"Vocabulary size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98c02fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d34181d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(X_padding, y, test_size=0.3, random_state=seed, stratify=y)\n",
    "X_test,X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=0.5, random_state=seed, stratify=y_test_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85415151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\ai_env\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 150ms/step - accuracy: 0.6483 - loss: 0.6152 - val_accuracy: 0.8511 - val_loss: 0.3420\n",
      "Epoch 2/10\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 143ms/step - accuracy: 0.9286 - loss: 0.1956 - val_accuracy: 0.8746 - val_loss: 0.4128\n",
      "Epoch 3/10\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 141ms/step - accuracy: 0.9927 - loss: 0.0279 - val_accuracy: 0.8715 - val_loss: 0.5470\n",
      "Epoch 4/10\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 143ms/step - accuracy: 0.9979 - loss: 0.0095 - val_accuracy: 0.8793 - val_loss: 0.6164\n",
      "Epoch 5/10\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 147ms/step - accuracy: 0.9939 - loss: 0.0158 - val_accuracy: 0.8809 - val_loss: 0.5807\n",
      "Epoch 6/10\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 148ms/step - accuracy: 0.9953 - loss: 0.0193 - val_accuracy: 0.8840 - val_loss: 0.5288\n",
      "Epoch 7/10\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 168ms/step - accuracy: 0.9962 - loss: 0.0142 - val_accuracy: 0.8683 - val_loss: 0.5462\n",
      "Epoch 8/10\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 191ms/step - accuracy: 0.9975 - loss: 0.0058 - val_accuracy: 0.8668 - val_loss: 0.5823\n",
      "Epoch 9/10\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 165ms/step - accuracy: 0.9996 - loss: 0.0019 - val_accuracy: 0.8762 - val_loss: 0.6317\n",
      "Epoch 10/10\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 161ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.8683 - val_loss: 0.6895\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, Bidirectional, Dropout\n",
    "from keras.losses import BinaryCrossentropy\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=300, input_length=128))\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Bidirectional(LSTM(32)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))  # Assuming binary classification, change to 'softmax' for multi-class\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2a91796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.8458 - loss: 1.0129\n",
      "Test Loss: 1.0796666145324707, Test Accuracy: 0.8354231715202332\n"
     ]
    }
   ],
   "source": [
    "eval =model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {eval[0]}, Test Accuracy: {eval[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f2faf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60b77a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1db9bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
